{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "warprnnt_numba_vs_torch_audio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq4tJykSe_eE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e720394e-4550-437a-9d87-6ed27eb3b70e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (0.51.2)\n",
            "Collecting numba\n",
            "  Downloading numba-0.55.1-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.22,>=1.18 in /usr/local/lib/python3.7/dist-packages (from numba) (1.19.5)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 7.0 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (57.4.0)\n",
            "Installing collected packages: llvmlite, numba\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.38.0 numba-0.55.1\n"
          ]
        }
      ],
      "source": [
        "# Update numba and restart\n",
        "\n",
        "# In a conda environment, you would use the following command\n",
        "# Update Numba to > 0.54\n",
        "# conda install -c conda-forge numba>=0.54\n",
        "# or\n",
        "# conda update -c conda-forge numba>=0.54\n",
        "\n",
        "# For pip based environments,\n",
        "# Update Numba to > 0.54\n",
        "import os\n",
        "import signal\n",
        "\n",
        "!pip install --upgrade numba\n",
        "\n",
        "# This will kill the kernel, click next cell to import the latest numba\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive comparison between WarpRNNT Numba and Torchaudio RNNT [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/titu1994/warprnnt_numba/blob/master/scripts/naive_comparisons/warprnnt_numba_vs_torch_audio.ipynb)\n",
        "\n",
        "This notebook is a colab compatible way to do a **naive comparison** between the two loss functions. \n",
        "\n",
        "*Therefore no conclusions can be reached from this notebook, both are useful in many contexts.*\n",
        "\n",
        "-----\n",
        "\n",
        "Note that due to some dangling reference issue with running PyTorch `benchmark.Timer` with global variables for the inputs to the function, we will be writing the code in the notebook and in parallel exporting  the code snippets into a new file called `script.py` which will then be executed to write out the results.\n",
        "\n",
        "-----\n",
        "\n",
        "## THIS NOTEBOOK MUST BE RUN TOP TO BOTTOM ONLY. \n",
        "\n",
        "-----\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EHaf-XbRrZws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that a recent Numba version has been installed. Anything > 0.53 will do."
      ],
      "metadata": {
        "id": "83b1lg7Tsd8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "print(numba.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84lf3plWf6c-",
        "outputId": "2f20b912-7468-4163-9def-de7ecaad49d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.55.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the `warprnnt_numba` library from https://github.com/titu1994/warprnnt_numba.git"
      ],
      "metadata": {
        "id": "3h6YpSg9so89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/titu1994/warprnnt_numba.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmgxiF1vfqa0",
        "outputId": "71f8ef2e-3454-48f5-98c0-6e6ba88bdc6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/titu1994/warprnnt_numba.git\n",
            "  Cloning https://github.com/titu1994/warprnnt_numba.git to /tmp/pip-req-build-qg1cdna3\n",
            "  Running command git clone -q https://github.com/titu1994/warprnnt_numba.git /tmp/pip-req-build-qg1cdna3\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from warprnnt-numba==0.4.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from warprnnt-numba==0.4.0) (0.55.1)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.4.0) (0.38.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.4.0) (57.4.0)\n",
            "Requirement already satisfied: numpy<1.22,>=1.18 in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->warprnnt-numba==0.4.0) (3.10.0.2)\n",
            "Building wheels for collected packages: warprnnt-numba\n",
            "  Building wheel for warprnnt-numba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warprnnt-numba: filename=warprnnt_numba-0.4.0-py2.py3-none-any.whl size=46593 sha256=fb860d7b7248fd879ce4551f3cb5efe7359fe1e8f6013fdb744ee8e97ca08848\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cjg4enth/wheels/4f/a0/b1/077219f288994e18d6b0fb5bf326931aecce95cdc804e5203d\n",
            "Successfully built warprnnt-numba\n",
            "Installing collected packages: warprnnt-numba\n",
            "Successfully installed warprnnt-numba-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility IPython Magic functions\n",
        "\n",
        "The following two functions are to denote cells that export their code content into `scripts.py`. \n",
        "\n",
        "-----\n",
        "\n",
        "## NOTE\n",
        "\n",
        "Rerunning a cell multiple times will duplicate the code inside the script, so only run this notebook top to bottom and return here to run again !"
      ],
      "metadata": {
        "id": "7UylHQf4svkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def exec_write_cell(line, cell):\n",
        "    # Run and save python code block to a file\n",
        "\n",
        "    with open(line, 'a', encoding='utf8') as pyf:\n",
        "        pyf.write(cell)\n",
        "        pyf.write(\"\\n\\n\")\n",
        "\n",
        "    code = compile(cell, line, 'exec')\n",
        "    exec(code, globals())\n",
        "    print(\"---> wrote cells to file :\", line)\n",
        "\n",
        "@register_cell_magic\n",
        "def write_cell(line, cell):\n",
        "    # Save python code block to a file, but do not run it.\n",
        "\n",
        "    with open(line, 'a', encoding='utf8') as pyf:\n",
        "        pyf.write(cell)\n",
        "        pyf.write(\"\\n\\n\")\n",
        "\n",
        "    print(\"---> wrote cells to file (and did not execute):\", line)"
      ],
      "metadata": {
        "id": "7SffNvdEWbWG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Be sure to delete the file cells if creating a new \n",
        "if os.path.exists('script.py'):\n",
        "  os.remove('script.py')"
      ],
      "metadata": {
        "id": "neo_P7eUYbg-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import os\n",
        "\n",
        "print(\"Torch :\", torch.__version__)\n",
        "print(\"Torch Audio:\", torchaudio.__version__)\n",
        "print(\"[Note]: Torch audio version must be >= 0.10.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdvtukmUgrLA",
        "outputId": "e3064917-41d0-4742-a955-ad463a8e0c0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch : 1.10.0+cu111\n",
            "Torch Audio: 0.10.0+cu111\n",
            "[Note]: Torch audio version must be >= 0.10.0\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "import warprnnt_numba\n",
        "print(\"warprnnt_numba:\", warprnnt_numba.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgGYHW9qfkAv",
        "outputId": "6638d382-e80c-4d7c-da33-a06736a67b5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warprnnt_numba: 0.4.0\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "import numba\n",
        "cuda_supported = warprnnt_numba.numba_utils.numba_cuda_is_supported(numba.__version__)\n",
        "print(\"Numba supports CUDA:\", cuda_supported)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtPbeoKalFNo",
        "outputId": "05c28dc4-9428-4690-9817-0c46d200ec96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numba supports CUDA: True\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper methods \n",
        "\n",
        "Below are some helper methods that will build the loss functions and then call them on some random data. \n",
        "\n",
        "-----\n",
        "\n",
        "Note that for a given set of input arguments to `data_gen()`, the seeds are set in such a way that if the shape matches (via variable `bs`, `t`, `u` and `v`) then the same tensor is generated. This is for fair comparison between same inputs for two different loss functions. "
      ],
      "metadata": {
        "id": "JxAyYxYz1-3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import subprocess\n",
        "import traceback\n",
        "\n",
        "import torch\n",
        "import torch.utils.benchmark as benchmark\n",
        "\n",
        "from torchaudio.transforms import RNNTLoss\n",
        "from warprnnt_numba.rnnt_loss import RNNTLossNumba\n",
        "\n",
        "\n",
        "DEVICE = 'cuda'"
      ],
      "metadata": {
        "id": "msYY_7CejIUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b4d362-75d0-467d-855c-abfea0b29dcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Losses\n",
        "\n",
        "For comparison, we use <br>\n",
        "1) Torchaudio RNNT Loss <br>\n",
        "2) Numba WarpRNNT Loss <br>\n",
        "\n",
        "-----\n",
        "\n",
        "Differences between the two losses - \n",
        "* Torchaudio does not currently support [FastEmit Regulization](https://arxiv.org/abs/2010.11148). For such cases we skip the calculation of the loss and leave the result a blank row.\n",
        "\n",
        "* Numba does not currently support float16 CUDA calls, therefore we will test only fp32. If a fp16 tensor is passed to Numba loss, it will explicitly upcast it fp32 before computing the loss (at the cost of 2x memory for the input tensor). \n",
        "\n",
        "* Sometimes at Batch size 32 and large dimensions of T, U and V, Torchaudio RNNT loss sometimes hard crashes with cuda illegal memory access error. Its not always, but when it occurs try catch doesnt help since it corrupts the CUDA context and requires the script to be rerun. Maybe its something with GPU config but I havent debugged it, so for now those configurations will be commented out and skipped.\n"
      ],
      "metadata": {
        "id": "B5XTtQCRuHkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "global x, x_len, y, y_len\n",
        "\n",
        "def data_gen(bs, t=200, u=100, v=1024, dtype=torch.float32):\n",
        "    global x, x_len, y, y_len\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    shape = [bs, t, u, v + 1]\n",
        "    torch.manual_seed(0)\n",
        "    x = torch.randn(*shape, dtype=dtype, device=DEVICE, requires_grad=False)\n",
        "    x_len = torch.randint(t, size=[bs], device=DEVICE, dtype=torch.int32)\n",
        "    y = torch.randint(v, size=[bs, u - 1], device=DEVICE, dtype=torch.int32)\n",
        "    y_len = torch.randint(u, size=[bs], device=DEVICE, dtype=torch.int32)\n",
        "\n",
        "    # enforce some RNNT input constraints\n",
        "    rand_idx = torch.randint(bs, size=[1])\n",
        "    x_len[rand_idx] = t\n",
        "    y_len[rand_idx] = u - 1\n",
        "\n",
        "    return x, x_len, y, y_len\n",
        "\n",
        "\n",
        "def check_time_pt(x, x_len, y, y_len, fastemit_lambda=None, clamp=-1.0):\n",
        "    blank = x.shape[-1] - 1\n",
        "    rnnt_loss = RNNTLoss(blank=blank, clamp=clamp, reduction=\"none\")\n",
        "\n",
        "    try:\n",
        "        _ = rnnt_loss(logits=x, targets=y, logit_lengths=x_len, target_lengths=y_len)\n",
        "    except NotImplementedError:\n",
        "        print()\n",
        "        print(\"RNNT Loss not available on this platform. Could not compute Pytorch Audio RNNT Loss.\")\n",
        "        print(\"Original error below :\")\n",
        "        print(traceback.format_exc())\n",
        "        exit(1)\n",
        "\n",
        "\n",
        "def check_time_numba(x, x_len, y, y_len, fastemit_lambda=0.0, clamp=-1.0):\n",
        "    blank = x.shape[-1] - 1\n",
        "    rnnt_loss = RNNTLossNumba(blank=blank, reduction='none', fastemit_lambda=fastemit_lambda, clamp=clamp)\n",
        "\n",
        "    # Numba doesnt support fp16\n",
        "    if x.dtype != torch.float32:\n",
        "        x = x.float()\n",
        "\n",
        "    _ = rnnt_loss(acts=x, labels=y, act_lens=x_len, label_lens=y_len)\n",
        "\n",
        "\n",
        "def load_results(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "def save_results(results, path):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(results, f)"
      ],
      "metadata": {
        "id": "TnhYfzIolEFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95abe3c-5150-47dd-98d7-8aafd757d482"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Info\n",
        "\n",
        "The script should emit some key info such as which GPU is being used, how much memory it has and how much is free/allocated at the moment."
      ],
      "metadata": {
        "id": "8WrQLJnLwKGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "# Print CUDA environment\n",
        "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, encoding='utf-8')\n",
        "print(result.stdout)\n",
        "result = subprocess.run(['nvidia-smi', '-L'], capture_output=True, text=True, encoding='utf-8')\n",
        "print(result.stdout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR6N8mNC3aNI",
        "outputId": "125d9d61-64e8-4dcb-cbb0-d0759018cf4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 30 10:04:18 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    33W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "GPU 0: Tesla K80 (UUID: GPU-384e4707-b461-a2ea-5d08-cc02fc331056)\n",
            "\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(\"GPU Memory :\", torch.cuda.memory_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIoG4_mq5Uw7",
        "outputId": "363b3981-7d15-41d8-a0b2-605ecb5685fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Memory : |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "basedir = f\"results/numba_vs_torch_audio/\"\n",
        "if not os.path.exists(basedir):\n",
        "    os.makedirs(basedir, exist_ok=True)"
      ],
      "metadata": {
        "id": "YDpe6z_e6TCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20abc32b-5e49-446b-aa63-ddbd5876f2bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core script\n",
        "\n",
        "This cell is the main portion of the notebook, which normally should execute with certain combinations noted below.\n",
        "\n",
        "However, during testing it seems memory is not properly released inside the loop even with explicit None cast and global variables to prevent duplicate referrences. So this snippet simply writes out to the script instead of executing itself.\n",
        "\n",
        "-----\n",
        "\n",
        "### Permutations\n",
        "\n",
        "The ranges have been selected for general Librispeech training. \n",
        "\n",
        "Batch size depends on the variable `REQUIRES_GRAD`. Since gradient shape is same as shape of the input joint, it requires roughly 2x the memory so batch size must be halved. \n",
        "\n",
        "* `b`: [1, 4, 8, 16]. [32] is added if loss is being computed for inference only. 32 GB memory can go upto 64 with Numba for inference and 32 for training.\n",
        "* `t`: [200, 400]. Average length of LS is 16 seconds, with 4x stride ~ 400 timesteps, and with 8x stride of encoder its ~ 200 timesteps.\n",
        "* `u`: [100, 200]. Depends on how the text was encoded - character encoding (upto 400+ characters) to subword encoding (100-200 sub-words). \n",
        "* `v`: [28, 1024]. Represents vocabulary size of the model. 28 is for character encoding - 26 lower case alphabet, space and apostrophe. 1024 is for sub-word encoding with fixed vocabulary size - Google papers tend towards 1024 for their RNNT models (though some are upto 4096).\n",
        "* `fastemit_lambda`: [0.0, 0.001]. FastEmit regularization strength. 0.0 means it is disabled, and any value > 0 will perform fastemit regularization for numba loss. Skipped for Torchaudio loss.\n",
        "* `dtype`: [torch.float32]. Fixed to float32 for now, since we cant do the largest test suite due to memory constraints. Will be removed once numba supports float16 for CUDA.\n",
        "* `clamp`: [-1, 0.1]. Factor for gradient clamping. If -1, it is disabled and any value > 0 will enable the gradient clamping step in numba and torchaudio losses."
      ],
      "metadata": {
        "id": "OH3xcfBewVFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "REQUIRES_GRAD = True\n",
        "\n",
        "print(\"Gradients will be computed :\", REQUIRES_GRAD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSn9sOKUv_UI",
        "outputId": "103986b3-0532-4069-c051-1135cc584b98"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients will be computed : True\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_cell script.py\n",
        "\n",
        "# Compare takes a list of measurements which we'll save in results.\n",
        "global results\n",
        "results = []\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
        "save_results(results, results_path)\n",
        "del results\n",
        "\n",
        "\n",
        "batchsizes = [1, 4, 8, 16]\n",
        "\n",
        "if not REQUIRES_GRAD:\n",
        "  batchsizes.append(32)\n",
        "\n",
        "for b in batchsizes:  # 1, 4, 8, 16, 32, 64 (on 32 GB GPUs)\n",
        "    for t in [200, 400]:  # 200, 400, 600 (LibriSpeech with 4x and 8x stride, on 32 GB GPUs)\n",
        "        for u in [100, 200]:  # 100, 200  # (char enc, subword enc)\n",
        "            for v in [28, 1024,]:  # 28, 1024  # (char encoding, Conformer RNNT Vocab Size)\n",
        "                for fastemit_lambda in [0.0, 0.001]:  # 0.0, 0.001  # (Google FastEmit regularization, no extra memory)\n",
        "                    for dtype in [torch.float32]:  # (AMP / FP32; Note: Numba impl will force cast to fp32)\n",
        "                        for clamp in [-1.0, 0.1]:  # Gradient clamping\n",
        "                            global x, x_len, y, y_len\n",
        "                            x = None\n",
        "                            x_len = None\n",
        "                            y = None\n",
        "                            y_len = None\n",
        "\n",
        "                            torch.cuda.empty_cache()\n",
        "\n",
        "                            # label and sub_label are the rows\n",
        "                            # description is the column\n",
        "                            label = 'RNNTLoss'\n",
        "                            sub_label = (\n",
        "                                f'[b={b}, t={t}, u={u}, v={v}, '\n",
        "                                f'fastemit_lambda={fastemit_lambda}, '\n",
        "                                f'clamp={clamp}, '\n",
        "                                f'dtype={dtype}]'\n",
        "                            )\n",
        "\n",
        "                            print(\"Computing :\", sub_label)\n",
        "\n",
        "                            # Pytorch Audio\n",
        "                            env = 'TorchAudio'\n",
        "\n",
        "                            if fastemit_lambda == 0.0:\n",
        "                                x, x_len, y, y_len = data_gen(b, t, u, v, dtype=dtype)\n",
        "\n",
        "                                if REQUIRES_GRAD:\n",
        "                                  x.requires_grad = True\n",
        "\n",
        "                                # Weird case of cuda illegal mem access beyond this config for fp 16 / fp 32 for batchsize=32\n",
        "                                # TODO: debug if its hardware issue or something else.\n",
        "                                # Works uptil b=32, t=329, u=200, v=1024 then fails above that for fp16\n",
        "                                # Also, setup b=32, t=600, u=100, v=1024 and above fails for fp32\n",
        "                                if (b * t * u * v) < (2 ** 31):\n",
        "                                    # fmt: off\n",
        "                                    t0 = benchmark.Timer(\n",
        "                                        stmt='check_time_pt(x, x_len, y, y_len, fastemit_lambda, clamp)',\n",
        "                                        setup=\"from __main__ import check_time_pt;\",\n",
        "                                        globals={'x': x, 'x_len': x_len, 'y': y, 'y_len': y_len,\n",
        "                                                  'fastemit_lambda': fastemit_lambda, 'clamp': clamp},\n",
        "                                        label=label,\n",
        "                                        sub_label=sub_label,\n",
        "                                        description=env,\n",
        "                                        num_threads=torch.get_num_threads(),\n",
        "                                    ).blocked_autorange(min_run_time=1.0)\n",
        "                                    # fmt: on\n",
        "\n",
        "                                    results = load_results(results_path)\n",
        "                                    results.append(t0)\n",
        "                                    save_results(results, results_path)\n",
        "                                    del results, t0\n",
        "                                    \n",
        "                                del x, x_len, y_len\n",
        "                                \n",
        "                            torch.cuda.empty_cache()\n",
        "\n",
        "                            # Numba\n",
        "                            env = 'Numba'\n",
        "                            x, x_len, y, y_len = data_gen(b, t, u, v, dtype=dtype)\n",
        "\n",
        "                            if REQUIRES_GRAD:\n",
        "                                  x.requires_grad = True\n",
        "\n",
        "                            # fmt: off\n",
        "                            t0 = benchmark.Timer(\n",
        "                                stmt='check_time_numba(x, x_len, y, y_len, fastemit_lambda, clamp);',\n",
        "                                setup=\"from __main__ import check_time_numba;\",\n",
        "                                globals={'x': x, 'x_len': x_len, 'y': y, 'y_len': y_len,\n",
        "                                          'fastemit_lambda': fastemit_lambda, 'clamp': clamp},\n",
        "                                label=label,\n",
        "                                sub_label=sub_label,\n",
        "                                description=env,\n",
        "                                num_threads=torch.get_num_threads(),\n",
        "                            ).blocked_autorange(min_run_time=1.0)\n",
        "                            # fmt: on\n",
        "\n",
        "                            results = load_results(results_path)\n",
        "                            results.append(t0)\n",
        "                            save_results(results, results_path)\n",
        "                            del results, t0\n",
        "\n",
        "                            del x, x_len, y, y_len\n",
        "                            torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPDUgiZhlTEJ",
        "outputId": "020b2277-12b8-49ad-bd8d-26e966152598"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> wrote cells to file (and did not execute): script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute script\n",
        "\n",
        "Now that the script has the code contents necessary to perform the evaluations, execute it from the shell"
      ],
      "metadata": {
        "id": "FctYHrZLzV1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training mode"
      ],
      "metadata": {
        "id": "-3BS1JaVy8v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python script.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xqum-zROWpLC",
        "outputId": "832302da-8fa5-4225-df6e-7979c1c3f1dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch : 1.10.0+cu111\n",
            "Torch Audio: 0.10.0+cu111\n",
            "[Note]: Torch audio version must be >= 0.10.0\n",
            "warprnnt_numba: 0.4.0\n",
            "Numba supports CUDA: True\n",
            "Sun Jan 30 10:04:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    33W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "GPU 0: Tesla K80 (UUID: GPU-384e4707-b461-a2ea-5d08-cc02fc331056)\n",
            "\n",
            "GPU Memory : |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "Gradients will be computed : True\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (4) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (8) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (16) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print out results\n",
        "\n",
        "Since the output has been written to a pickle file, print out the output of the script above."
      ],
      "metadata": {
        "id": "aOtw0lHxz2lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print()\n",
        "\n",
        "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
        "results = load_results(results_path)\n",
        "compare = benchmark.Compare(results)\n",
        "compare.colorize()\n",
        "compare.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y80iSqdMlV1s",
        "outputId": "08cf071d-e4c2-4c7e-b028-47f4f86584ef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[---------------------------------------------------- RNNTLoss ---------------------------------------------------]\n",
            "                                                                                            |  TorchAudio  |  Numba\n",
            "1 threads: --------------------------------------------------------------------------------------------------------\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[92m\u001b[1m    3.8   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  8.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[34m\u001b[1m    3.8   \u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m  7.7\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[92m\u001b[1m  7.7\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[34m\u001b[1m  7.8\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   21.5   \u001b[0m\u001b[0m  |    9.6\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   24.9   \u001b[0m\u001b[0m  |    9.9\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |   10.3\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |   10.5\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      7.3     |    9.4\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    7.8   \u001b[0m\u001b[0m  |    9.5\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    9.5\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    9.5\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   57.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 17.0\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   76.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 17.0\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 18.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 18.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      6.3     |   10.3\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      6.4     |   10.3\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |   10.2\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |   10.4\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   80.0   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 17.8\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   88.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 17.8\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 18.9\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 18.9\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m   12.4   \u001b[0m\u001b[0m  |   13.8\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m   12.6   \u001b[0m\u001b[0m  |   13.8\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |   13.8\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |   13.9\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  163.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 32.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  188.4   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 32.5\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 34.6\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 34.7\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    8.8   \u001b[0m\u001b[0m  |   10.0\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    9.0   \u001b[0m\u001b[0m  |   10.0\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    9.9\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |   10.0\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   47.7   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 23.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   55.0   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 23.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 25.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 25.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m   16.2   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 16.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m   16.5   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 16.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 16.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 16.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  118.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 45.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  153.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 46.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 48.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 48.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m   15.4   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 16.7\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m   15.7   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 16.7\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 16.6\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 16.6\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  124.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 45.4\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  133.7   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 45.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 47.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 47.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   27.2   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 28.3\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   27.5   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 28.3\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 28.4\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 28.5\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  300.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 90.4\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  361.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 90.7\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 95.3\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 95.5\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m   15.8   \u001b[0m\u001b[0m  |   14.8\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m   16.1   \u001b[0m\u001b[0m  |   14.8\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |   14.8\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |   14.8\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   89.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 44.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   99.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 44.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 46.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 46.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   33.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 26.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   34.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 26.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 26.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 26.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  196.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 84.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  246.7   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 84.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 88.5\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 88.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   27.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 26.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   27.4   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 26.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 26.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 26.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  234.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 85.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  250.5   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 85.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 88.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 88.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   51.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 48.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   51.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 48.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 48.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[31m\u001b[1m 48.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  329.5   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m154.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  386.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m154.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m159.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m159.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   27.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 24.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   28.2   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 24.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 24.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 24.4\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  106.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 76.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  120.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 76.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 78.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 78.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   55.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 45.4\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   56.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 45.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 45.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 45.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  265.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m153.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  325.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m153.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m157.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m159.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   47.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 46.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   48.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 46.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 46.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 46.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  366.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m158.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  393.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m158.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m163.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m164.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m  111.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 91.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m  113.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 91.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 92.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 92.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  642.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m301.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  774.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m300.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m308.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m310.4\u001b[0m\u001b[0m\n",
            "\n",
            "Times are in milliseconds (ms).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Mode"
      ],
      "metadata": {
        "id": "E7_umfTVy51d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/REQUIRES_GRAD = True/REQUIRES_GRAD = False/g' script.py\n",
        "!python script.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EWrh_4Tyrap",
        "outputId": "a8ec667a-041e-49f0-eef9-d3dea81036e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch : 1.10.0+cu111\n",
            "Torch Audio: 0.10.0+cu111\n",
            "[Note]: Torch audio version must be >= 0.10.0\n",
            "warprnnt_numba: 0.4.0\n",
            "Numba supports CUDA: True\n",
            "Sun Jan 30 10:11:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    32W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "GPU 0: Tesla K80 (UUID: GPU-384e4707-b461-a2ea-5d08-cc02fc331056)\n",
            "\n",
            "GPU Memory : |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "Gradients will be computed : False\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (4) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (8) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (16) < 2 * SM count (26) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print out results\n",
        "\n",
        "Since the output has been written to a pickle file, print out the output of the script above."
      ],
      "metadata": {
        "id": "VDf12SvNzUBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print()\n",
        "\n",
        "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
        "results = load_results(results_path)\n",
        "compare = benchmark.Compare(results)\n",
        "compare.colorize()\n",
        "compare.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oVfaIEgzGIZ",
        "outputId": "d3316b6b-93df-4759-c141-ef3db480bbc9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[---------------------------------------------------- RNNTLoss ---------------------------------------------------]\n",
            "                                                                                            |  TorchAudio  |  Numba\n",
            "1 threads: --------------------------------------------------------------------------------------------------------\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[92m\u001b[1m    3.8   \u001b[0m\u001b[0m  |    7.8\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[34m\u001b[1m    3.8   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  5.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[34m\u001b[1m  5.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[92m\u001b[1m  5.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   21.6   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  5.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   24.8   \u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m  5.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[34m\u001b[1m  5.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[34m\u001b[1m  5.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      7.3     |    5.8\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      7.4     |    5.8\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    5.8\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    5.8\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   57.4   \u001b[0m\u001b[0m  |    7.5\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   75.9   \u001b[0m\u001b[0m  |    7.5\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    7.5\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    7.5\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      6.3     |    6.4\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      6.4     |    6.4\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    6.3\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    6.3\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   80.1   \u001b[0m\u001b[0m  |    8.0\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   88.1   \u001b[0m\u001b[0m  |    8.0\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    8.0\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    8.0\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m   12.4   \u001b[0m\u001b[0m  |    7.2\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m   12.6   \u001b[0m\u001b[0m  |    7.2\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    7.2\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    7.2\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  163.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.4\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  188.4   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.5\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 12.5\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 12.5\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    8.8   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  5.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    9.0   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  5.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[34m\u001b[1m  5.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[34m\u001b[1m  5.3\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   47.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 10.4\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   54.8   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 10.4\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 10.5\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 10.6\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m   16.2   \u001b[0m\u001b[0m  |    7.8\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m   16.5   \u001b[0m\u001b[0m  |    7.8\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    7.8\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    7.8\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  118.7   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 18.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  152.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 18.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 18.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 18.7\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m   15.4   \u001b[0m\u001b[0m  |    8.3\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m   15.7   \u001b[0m\u001b[0m  |    8.3\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    8.3\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    8.3\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  124.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 19.3\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  133.3   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 19.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 19.3\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 19.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   27.2   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   27.5   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 13.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 13.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  299.7   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.4\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  361.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.6\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 35.4\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 35.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m   15.9   \u001b[0m\u001b[0m  |    7.1\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m   16.2   \u001b[0m\u001b[0m  |    7.2\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    7.1\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    7.1\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   86.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 18.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   98.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 18.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 18.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 18.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   33.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   34.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 11.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 11.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  196.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 34.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  248.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 34.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 34.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 34.5\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   27.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   27.4   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 12.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 12.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  234.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  250.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 34.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 35.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   51.4   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 20.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   52.0   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 20.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 20.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 20.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  328.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 66.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  389.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 66.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 66.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 67.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   27.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   28.2   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 11.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 11.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  106.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 33.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  120.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 33.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 33.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 33.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   56.0   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 19.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   56.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 19.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 19.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 19.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  265.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 66.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  323.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 65.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 66.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 65.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   47.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 20.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   48.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 20.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 20.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 20.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  365.8   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 66.4\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  392.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 66.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 66.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 66.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m  111.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 36.4\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m  112.8   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 36.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 36.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 36.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  642.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m130.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  776.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m132.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m129.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m130.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   53.3   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 18.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   54.3   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 18.8\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 18.8\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 18.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  244.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 65.6\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  278.7   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 65.7\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 65.7\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 65.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m  120.8   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m  123.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 35.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 35.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  530.5   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m130.1\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  633.7   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m129.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m130.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m129.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   99.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.8\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m  100.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.6\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 35.7\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 35.7\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  610.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m130.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  655.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m130.4\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m131.1\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m129.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m  216.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 68.1\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m  218.5   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 68.0\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 68.1\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 68.0\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m259.0\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m258.1\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m258.4\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m258.3\u001b[0m\u001b[0m\n",
            "\n",
            "Times are in milliseconds (ms).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q5c6QxuurbNO"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}