{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "warprnnt_numba_vs_torch_audio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq4tJykSe_eE"
      },
      "outputs": [],
      "source": [
        "# Update numba and restart\n",
        "\n",
        "# In a conda environment, you would use the following command\n",
        "# Update Numba to > 0.54\n",
        "# conda install -c conda-forge numba>=0.54\n",
        "# or\n",
        "# conda update -c conda-forge numba>=0.54\n",
        "\n",
        "# For pip based environments,\n",
        "# Update Numba to > 0.54\n",
        "import os\n",
        "import signal\n",
        "\n",
        "!pip install --upgrade numba\n",
        "\n",
        "# This will kill the kernel, click next cell to import the latest numba\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive comparison between WarpRNNT Numba and Torchaudio RNNT [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/titu1994/warprnnt_numba/blob/master/scripts/naive_comparisons/warprnnt_numba_vs_torch_audio.ipynb)\n",
        "\n",
        "This notebook is a colab compatible way to do a **naive comparison** between the two loss functions. \n",
        "\n",
        "*Therefore no conclusions can be reached from this notebook, both are useful in many contexts.*\n",
        "\n",
        "-----\n",
        "\n",
        "Note that due to some dangling reference issue with running PyTorch `benchmark.Timer` with global variables for the inputs to the function, we will be writing the code in the notebook and in parallel exporting  the code snippets into a new file called `script.py` which will then be executed to write out the results.\n",
        "\n",
        "-----\n",
        "\n",
        "## THIS NOTEBOOK MUST BE RUN TOP TO BOTTOM ONLY. \n",
        "\n",
        "-----\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EHaf-XbRrZws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that a recent Numba version has been installed. Anything > 0.53 will do."
      ],
      "metadata": {
        "id": "83b1lg7Tsd8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "print(numba.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84lf3plWf6c-",
        "outputId": "d84c8b48-ca72-4825-c7a0-af7672678d37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.55.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the `warprnnt_numba` library from https://github.com/titu1994/warprnnt_numba.git"
      ],
      "metadata": {
        "id": "3h6YpSg9so89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/titu1994/warprnnt_numba.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmgxiF1vfqa0",
        "outputId": "6ed0b48a-2a19-496f-95cd-042184464d40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/titu1994/warprnnt_numba.git\n",
            "  Cloning https://github.com/titu1994/warprnnt_numba.git to /tmp/pip-req-build-jww_v_o6\n",
            "  Running command git clone -q https://github.com/titu1994/warprnnt_numba.git /tmp/pip-req-build-jww_v_o6\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from warprnnt-numba==0.2.2) (1.10.0+cu111)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from warprnnt-numba==0.2.2) (0.55.0)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.2.2) (0.38.0)\n",
            "Requirement already satisfied: numpy<1.22,>=1.18 in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.2.2) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->warprnnt-numba==0.2.2) (3.10.0.2)\n",
            "Building wheels for collected packages: warprnnt-numba\n",
            "  Building wheel for warprnnt-numba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warprnnt-numba: filename=warprnnt_numba-0.2.2-py2.py3-none-any.whl size=35308 sha256=fbaec24eaf92d23219bb5723bd85ad17a9c5c37d3daaf15341540336276b5d95\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7s2ghtke/wheels/4f/a0/b1/077219f288994e18d6b0fb5bf326931aecce95cdc804e5203d\n",
            "Successfully built warprnnt-numba\n",
            "Installing collected packages: warprnnt-numba\n",
            "Successfully installed warprnnt-numba-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility IPython Magic functions\n",
        "\n",
        "The following two functions are to denote cells that export their code content into `scripts.py`. \n",
        "\n",
        "-----\n",
        "\n",
        "## NOTE\n",
        "\n",
        "Rerunning a cell multiple times will duplicate the code inside the script, so only run this notebook top to bottom and return here to run again !"
      ],
      "metadata": {
        "id": "7UylHQf4svkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def exec_write_cell(line, cell):\n",
        "    # Run and save python code block to a file\n",
        "\n",
        "    with open(line, 'a', encoding='utf8') as pyf:\n",
        "        pyf.write(cell)\n",
        "        pyf.write(\"\\n\\n\")\n",
        "\n",
        "    code = compile(cell, line, 'exec')\n",
        "    exec(code, globals())\n",
        "    print(\"---> wrote cells to file :\", line)\n",
        "\n",
        "@register_cell_magic\n",
        "def write_cell(line, cell):\n",
        "    # Save python code block to a file, but do not run it.\n",
        "\n",
        "    with open(line, 'a', encoding='utf8') as pyf:\n",
        "        pyf.write(cell)\n",
        "        pyf.write(\"\\n\\n\")\n",
        "\n",
        "    print(\"---> wrote cells to file (and did not execute):\", line)"
      ],
      "metadata": {
        "id": "7SffNvdEWbWG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Be sure to delete the file cells if creating a new \n",
        "if os.path.exists('script.py'):\n",
        "  os.remove('script.py')"
      ],
      "metadata": {
        "id": "neo_P7eUYbg-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import os\n",
        "\n",
        "print(\"Torch :\", torch.__version__)\n",
        "print(\"Torch Audio:\", torchaudio.__version__)\n",
        "print(\"[Note]: Torch audio version must be >= 0.10.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdvtukmUgrLA",
        "outputId": "c2b653ff-7206-454e-9aa0-a7bae8236efe"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch : 1.10.0+cu111\n",
            "Torch Audio: 0.10.0+cu111\n",
            "[Note]: Torch audio version must be >= 0.10.0\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "import warprnnt_numba\n",
        "print(\"warprnnt_numba:\", warprnnt_numba.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgGYHW9qfkAv",
        "outputId": "d471895f-b435-4114-d984-bba8ca66ed5d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warprnnt_numba: 0.2.2\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "import numba\n",
        "cuda_supported = warprnnt_numba.numba_utils.numba_cuda_is_supported(numba.__version__)\n",
        "print(\"Numba supports CUDA:\", cuda_supported)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtPbeoKalFNo",
        "outputId": "7a81e263-dd16-4e8f-877e-bb3617e990a9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numba supports CUDA: True\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper methods \n",
        "\n",
        "Below are some helper methods that will build the loss functions and then call them on some random data. \n",
        "\n",
        "-----\n",
        "\n",
        "Note that for a given set of input arguments to `data_gen()`, the seeds are set in such a way that if the shape matches (via variable `bs`, `t`, `u` and `v`) then the same tensor is generated. This is for fair comparison between same inputs for two different loss functions. "
      ],
      "metadata": {
        "id": "JxAyYxYz1-3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import subprocess\n",
        "import traceback\n",
        "\n",
        "import torch\n",
        "import torch.utils.benchmark as benchmark\n",
        "\n",
        "from torchaudio.transforms import RNNTLoss\n",
        "from warprnnt_numba.rnnt_loss import RNNTLossNumba\n",
        "\n",
        "\n",
        "DEVICE = 'cuda'"
      ],
      "metadata": {
        "id": "msYY_7CejIUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb3dec0-c27d-49e2-959f-c5e77f9634ee"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Losses\n",
        "\n",
        "For comparison, we use <br>\n",
        "1) Torchaudio RNNT Loss <br>\n",
        "2) Numba WarpRNNT Loss <br>\n",
        "\n",
        "-----\n",
        "\n",
        "Differences between the two losses - \n",
        "* Torchaudio does not currently support [FastEmit Regulization](https://arxiv.org/abs/2010.11148). For such cases we skip the calculation of the loss and leave the result a blank row.\n",
        "\n",
        "* Numba does not currently support float16 CUDA calls, therefore we will test only fp32. If a fp16 tensor is passed to Numba loss, it will explicitly upcast it fp32 before computing the loss (at the cost of 2x memory for the input tensor). \n",
        "\n",
        "* Sometimes at Batch size 32 and large dimensions of T, U and V, Torchaudio RNNT loss sometimes hard crashes with cuda illegal memory access error. Its not always, but when it occurs try catch doesnt help since it corrupts the CUDA context and requires the script to be rerun. Maybe its something with GPU config but I havent debugged it, so for now those configurations will be commented out and skipped.\n"
      ],
      "metadata": {
        "id": "B5XTtQCRuHkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "global x, x_len, y, y_len\n",
        "\n",
        "def data_gen(bs, t=200, u=100, v=1024, dtype=torch.float32):\n",
        "    global x, x_len, y, y_len\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    shape = [bs, t, u, v + 1]\n",
        "    torch.manual_seed(0)\n",
        "    x = torch.randn(*shape, dtype=dtype, device=DEVICE, requires_grad=False)\n",
        "    x_len = torch.randint(t, size=[bs], device=DEVICE, dtype=torch.int32)\n",
        "    y = torch.randint(v, size=[bs, u - 1], device=DEVICE, dtype=torch.int32)\n",
        "    y_len = torch.randint(u, size=[bs], device=DEVICE, dtype=torch.int32)\n",
        "\n",
        "    # enforce some RNNT input constraints\n",
        "    rand_idx = torch.randint(bs, size=[1])\n",
        "    x_len[rand_idx] = t\n",
        "    y_len[rand_idx] = u - 1\n",
        "\n",
        "    return x, x_len, y, y_len\n",
        "\n",
        "\n",
        "def check_time_pt(x, x_len, y, y_len, fastemit_lambda=None, clamp=-1.0):\n",
        "    blank = x.shape[-1] - 1\n",
        "    rnnt_loss = RNNTLoss(blank=blank, clamp=clamp, reduction=\"none\")\n",
        "\n",
        "    try:\n",
        "        _ = rnnt_loss(logits=x, targets=y, logit_lengths=x_len, target_lengths=y_len)\n",
        "    except NotImplementedError:\n",
        "        print()\n",
        "        print(\"RNNT Loss not available on this platform. Could not compute Pytorch Audio RNNT Loss.\")\n",
        "        print(\"Original error below :\")\n",
        "        print(traceback.format_exc())\n",
        "        exit(1)\n",
        "\n",
        "\n",
        "def check_time_numba(x, x_len, y, y_len, fastemit_lambda=0.0, clamp=-1.0):\n",
        "    blank = x.shape[-1] - 1\n",
        "    rnnt_loss = RNNTLossNumba(blank=blank, reduction='none', fastemit_lambda=fastemit_lambda, clamp=clamp)\n",
        "\n",
        "    # Numba doesnt support fp16\n",
        "    if x.dtype != torch.float32:\n",
        "        x = x.float()\n",
        "\n",
        "    _ = rnnt_loss(acts=x, labels=y, act_lens=x_len, label_lens=y_len)\n",
        "\n",
        "\n",
        "def load_results(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    results = pickle.load(f)\n",
        "    return results\n",
        "\n",
        "def save_results(results, path):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(results, f)"
      ],
      "metadata": {
        "id": "TnhYfzIolEFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b856e91e-a30b-458c-bf01-da5e12067b5e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Info\n",
        "\n",
        "The script should emit some key info such as which GPU is being used, how much memory it has and how much is free/allocated at the moment."
      ],
      "metadata": {
        "id": "8WrQLJnLwKGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "# Print CUDA environment\n",
        "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, encoding='utf-8')\n",
        "print(result.stdout)\n",
        "result = subprocess.run(['nvidia-smi', '-L'], capture_output=True, text=True, encoding='utf-8')\n",
        "print(result.stdout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR6N8mNC3aNI",
        "outputId": "1aeadaed-4015-4996-afa6-d1fad58b3a30"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 25 19:44:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "GPU 0: Tesla T4 (UUID: GPU-57c36640-58c7-b34e-4e4f-ac4e9c622a0e)\n",
            "\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(\"GPU Memory :\", torch.cuda.memory_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIoG4_mq5Uw7",
        "outputId": "8072a5fc-269a-4a91-ae1f-f9942eb51518"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Memory : |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "basedir = f\"results/numba_vs_torch_audio/\"\n",
        "if not os.path.exists(basedir):\n",
        "    os.makedirs(basedir, exist_ok=True)"
      ],
      "metadata": {
        "id": "YDpe6z_e6TCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddffb6ca-6b4e-4232-9969-20900b52862c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core script\n",
        "\n",
        "This cell is the main portion of the notebook, which normally should execute with certain combinations noted below.\n",
        "\n",
        "However, during testing it seems memory is not properly released inside the loop even with explicit None cast and global variables to prevent duplicate referrences. So this snippet simply writes out to the script instead of executing itself.\n",
        "\n",
        "-----\n",
        "\n",
        "### Permutations\n",
        "\n",
        "The ranges have been selected for general Librispeech training. \n",
        "\n",
        "Batch size depends on the variable `REQUIRES_GRAD`. Since gradient shape is same as shape of the input joint, it requires roughly 2x the memory so batch size must be halved. \n",
        "\n",
        "* `b`: [1, 4, 8, 16]. [32] is added if loss is being computed for inference only. 32 GB memory can go upto 64 with Numba for inference and 32 for training.\n",
        "* `t`: [200, 400]. Average length of LS is 16 seconds, with 4x stride ~ 400 timesteps, and with 8x stride of encoder its ~ 200 timesteps.\n",
        "* `u`: [100, 200]. Depends on how the text was encoded - character encoding (upto 400+ characters) to subword encoding (100-200 sub-words). \n",
        "* `v`: [28, 1024]. Represents vocabulary size of the model. 28 is for character encoding - 26 lower case alphabet, space and apostrophe. 1024 is for sub-word encoding with fixed vocabulary size - Google papers tend towards 1024 for their RNNT models (though some are upto 4096).\n",
        "* `fastemit_lambda`: [0.0, 0.001]. FastEmit regularization strength. 0.0 means it is disabled, and any value > 0 will perform fastemit regularization for numba loss. Skipped for Torchaudio loss.\n",
        "* `dtype`: [torch.float32]. Fixed to float32 for now, since we cant do the largest test suite due to memory constraints. Will be removed once numba supports float16 for CUDA.\n",
        "* `clamp`: [-1, 0.1]. Factor for gradient clamping. If -1, it is disabled and any value > 0 will enable the gradient clamping step in numba and torchaudio losses."
      ],
      "metadata": {
        "id": "OH3xcfBewVFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%exec_write_cell script.py\n",
        "\n",
        "REQUIRES_GRAD = True\n",
        "\n",
        "print(\"Gradients will be computed :\", REQUIRES_GRAD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSn9sOKUv_UI",
        "outputId": "56f90c47-2c68-44a5-aa42-1bbef8a88d45"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients will be computed : True\n",
            "---> wrote cells to file : script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%write_cell script.py\n",
        "\n",
        "# Compare takes a list of measurements which we'll save in results.\n",
        "global results\n",
        "results = []\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
        "save_results(results, results_path)\n",
        "del results\n",
        "\n",
        "\n",
        "batchsizes = [1, 4, 8, 16]\n",
        "\n",
        "if not REQUIRES_GRAD:\n",
        "  batchsizes.append(32)\n",
        "\n",
        "for b in batchsizes:  # 1, 4, 8, 16, 32, 64 (on 32 GB GPUs)\n",
        "    for t in [200, 400]:  # 200, 400, 600 (LibriSpeech with 4x and 8x stride, on 32 GB GPUs)\n",
        "        for u in [100, 200]:  # 100, 200  # (char enc, subword enc)\n",
        "            for v in [28, 1024,]:  # 28, 1024  # (char encoding, Conformer RNNT Vocab Size)\n",
        "                for fastemit_lambda in [0.0, 0.001]:  # 0.0, 0.001  # (Google FastEmit regularization, no extra memory)\n",
        "                    for dtype in [torch.float32]:  # (AMP / FP32; Note: Numba impl will force cast to fp32)\n",
        "                        for clamp in [-1.0, 0.1]:  # Gradient clamping\n",
        "                            global x, x_len, y, y_len\n",
        "                            x = None\n",
        "                            x_len = None\n",
        "                            y = None\n",
        "                            y_len = None\n",
        "\n",
        "                            torch.cuda.empty_cache()\n",
        "\n",
        "                            # label and sub_label are the rows\n",
        "                            # description is the column\n",
        "                            label = 'RNNTLoss'\n",
        "                            sub_label = (\n",
        "                                f'[b={b}, t={t}, u={u}, v={v}, '\n",
        "                                f'fastemit_lambda={fastemit_lambda}, '\n",
        "                                f'clamp={clamp}, '\n",
        "                                f'dtype={dtype}]'\n",
        "                            )\n",
        "\n",
        "                            print(\"Computing :\", sub_label)\n",
        "\n",
        "                            # Pytorch Audio\n",
        "                            env = 'TorchAudio'\n",
        "\n",
        "                            if fastemit_lambda == 0.0:\n",
        "                                x, x_len, y, y_len = data_gen(b, t, u, v, dtype=dtype)\n",
        "\n",
        "                                if REQUIRES_GRAD:\n",
        "                                  x.requires_grad_ = True\n",
        "\n",
        "                                # Weird case of cuda illegal mem access beyond this config for fp 16 / fp 32 for batchsize=32\n",
        "                                # TODO: debug if its hardware issue or something else.\n",
        "                                # Works uptil b=32, t=329, u=200, v=1024 then fails above that for fp16\n",
        "                                # Also, setup b=32, t=600, u=100, v=1024 and above fails for fp32\n",
        "                                if (b * t * u * v) < (2 ** 31):\n",
        "                                    # fmt: off\n",
        "                                    t0 = benchmark.Timer(\n",
        "                                        stmt='check_time_pt(x, x_len, y, y_len, fastemit_lambda, clamp)',\n",
        "                                        setup=\"from __main__ import check_time_pt;\",\n",
        "                                        globals={'x': x, 'x_len': x_len, 'y': y, 'y_len': y_len,\n",
        "                                                  'fastemit_lambda': fastemit_lambda, 'clamp': clamp},\n",
        "                                        label=label,\n",
        "                                        sub_label=sub_label,\n",
        "                                        description=env,\n",
        "                                        num_threads=torch.get_num_threads(),\n",
        "                                    ).blocked_autorange(min_run_time=1.0)\n",
        "                                    # fmt: on\n",
        "\n",
        "                                    results = load_results(results_path)\n",
        "                                    results.append(t0)\n",
        "                                    save_results(results, results_path)\n",
        "                                    del results, t0\n",
        "                                    \n",
        "                                del x, x_len, y_len\n",
        "                                \n",
        "                            torch.cuda.empty_cache()\n",
        "\n",
        "                            # Numba\n",
        "                            env = 'Numba'\n",
        "                            x, x_len, y, y_len = data_gen(b, t, u, v, dtype=dtype)\n",
        "\n",
        "                            if REQUIRES_GRAD:\n",
        "                                  x.requires_grad_ = True\n",
        "\n",
        "                            # fmt: off\n",
        "                            t0 = benchmark.Timer(\n",
        "                                stmt='check_time_numba(x, x_len, y, y_len, fastemit_lambda, clamp);',\n",
        "                                setup=\"from __main__ import check_time_numba;\",\n",
        "                                globals={'x': x, 'x_len': x_len, 'y': y, 'y_len': y_len,\n",
        "                                          'fastemit_lambda': fastemit_lambda, 'clamp': clamp},\n",
        "                                label=label,\n",
        "                                sub_label=sub_label,\n",
        "                                description=env,\n",
        "                                num_threads=torch.get_num_threads(),\n",
        "                            ).blocked_autorange(min_run_time=1.0)\n",
        "                            # fmt: on\n",
        "\n",
        "                            results = load_results(results_path)\n",
        "                            results.append(t0)\n",
        "                            save_results(results, results_path)\n",
        "                            del results, t0\n",
        "\n",
        "                            del x, x_len, y, y_len\n",
        "                            torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPDUgiZhlTEJ",
        "outputId": "f68f560e-94dd-44e4-b5e2-39af44709b3d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> wrote cells to file (and did not execute): script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute script\n",
        "\n",
        "Now that the script has the code contents necessary to perform the evaluations, execute it from the shell"
      ],
      "metadata": {
        "id": "FctYHrZLzV1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training mode"
      ],
      "metadata": {
        "id": "-3BS1JaVy8v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python script.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xqum-zROWpLC",
        "outputId": "63c52cbf-bf8a-4e89-b96d-0e43cedc77d3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch : 1.10.0+cu111\n",
            "Torch Audio: 0.10.0+cu111\n",
            "[Note]: Torch audio version must be >= 0.10.0\n",
            "warprnnt_numba: 0.2.2\n",
            "Numba supports CUDA: True\n",
            "Tue Jan 25 19:44:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "GPU 0: Tesla T4 (UUID: GPU-57c36640-58c7-b34e-4e4f-ac4e9c622a0e)\n",
            "\n",
            "GPU Memory : |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "Gradients will be computed : True\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (4) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (8) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (16) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print out results\n",
        "\n",
        "Since the output has been written to a pickle file, print out the output of the script above."
      ],
      "metadata": {
        "id": "aOtw0lHxz2lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print()\n",
        "\n",
        "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
        "results = load_results(results_path)\n",
        "compare = benchmark.Compare(results)\n",
        "compare.colorize()\n",
        "compare.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y80iSqdMlV1s",
        "outputId": "25f1553a-4203-433a-ef60-731df8393d00"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[---------------------------------------------------- RNNTLoss ---------------------------------------------------]\n",
            "                                                                                            |  TorchAudio  |  Numba\n",
            "1 threads: --------------------------------------------------------------------------------------------------------\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[92m\u001b[1m    1.3   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  4.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[34m\u001b[1m    1.4   \u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m  3.9\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.3\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.3\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[2m\u001b[91m    5.9   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  4.0\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m    7.3   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  4.0\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[34m\u001b[1m  4.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[34m\u001b[1m  4.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.5     |  \u001b[34m\u001b[1m  4.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.6     |  \u001b[34m\u001b[1m  4.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.8\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.6\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   11.9   \u001b[0m\u001b[0m  |    4.4\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   15.5   \u001b[0m\u001b[0m  |    4.3\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    4.4\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    4.3\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.2     |  \u001b[34m\u001b[1m  4.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.2     |  \u001b[34m\u001b[1m  4.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.6\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.7\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   34.6   \u001b[0m\u001b[0m  |    4.4\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   31.3   \u001b[0m\u001b[0m  |    4.4\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    4.3\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    4.3\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    4.2   \u001b[0m\u001b[0m  |    4.6\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    4.3   \u001b[0m\u001b[0m  |    4.5\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.6\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.7\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   73.4   \u001b[0m\u001b[0m  |    6.1\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   65.6   \u001b[0m\u001b[0m  |    6.0\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    6.1\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    6.1\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.3     |    7.4\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.4     |    7.6\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m  7.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m  8.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   10.0   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  8.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   11.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  8.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m  8.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m  8.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    6.0   \u001b[0m\u001b[0m  |    7.6\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    6.2   \u001b[0m\u001b[0m  |    7.5\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m  7.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m  8.3\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   29.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   37.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 12.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 12.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    4.7   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  7.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    4.7   \u001b[0m\u001b[0m  |    7.7\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m  8.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m  8.6\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   45.2   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   43.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 12.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 11.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   10.0   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  8.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   10.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  8.7\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m  8.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m  9.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   89.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 20.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   86.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 20.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 20.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 20.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    4.7   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    4.8   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 12.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 13.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   20.8   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 16.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   24.5   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 17.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 16.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 17.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m    8.7   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m    8.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 14.5\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 16.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   42.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   51.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 23.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 22.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 23.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m    8.5   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m    8.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 15.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 16.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   65.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 23.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   63.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 23.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 22.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 22.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   16.3   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 15.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   16.5   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 15.5\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 16.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 16.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  136.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 35.9\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  143.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 36.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 36.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 36.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m    7.8   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m    7.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 24.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 25.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m   40.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 30.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m   46.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 31.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 30.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 31.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   18.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 25.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   18.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 24.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 26.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 27.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m   94.5   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 43.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  118.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 43.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 43.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 43.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   15.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 24.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   15.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 24.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 28.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 29.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  165.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 43.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  166.5   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 44.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 44.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 44.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   34.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 30.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   35.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 30.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 33.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 33.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  292.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 71.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  317.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 71.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 71.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 72.2\u001b[0m\u001b[0m\n",
            "\n",
            "Times are in milliseconds (ms).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Mode"
      ],
      "metadata": {
        "id": "E7_umfTVy51d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/REQUIRES_GRAD = True/REQUIRES_GRAD = False/g' script.py\n",
        "!python script.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EWrh_4Tyrap",
        "outputId": "31570111-bb8b-4eb4-fb0c-65aa785c7133"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch : 1.10.0+cu111\n",
            "Torch Audio: 0.10.0+cu111\n",
            "[Note]: Torch audio version must be >= 0.10.0\n",
            "warprnnt_numba: 0.2.2\n",
            "Numba supports CUDA: True\n",
            "Tue Jan 25 19:53:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "GPU 0: Tesla T4 (UUID: GPU-57c36640-58c7-b34e-4e4f-ac4e9c622a0e)\n",
            "\n",
            "GPU Memory : |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "Gradients will be computed : False\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (4) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (8) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (16) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:724: NumbaPerformanceWarning: Grid size (32) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
            "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print out results\n",
        "\n",
        "Since the output has been written to a pickle file, print out the output of the script above."
      ],
      "metadata": {
        "id": "VDf12SvNzUBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print()\n",
        "\n",
        "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
        "results = load_results(results_path)\n",
        "compare = benchmark.Compare(results)\n",
        "compare.colorize()\n",
        "compare.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oVfaIEgzGIZ",
        "outputId": "4b1b0671-67f7-4a9e-a488-e012eca82600"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[---------------------------------------------------- RNNTLoss ---------------------------------------------------]\n",
            "                                                                                            |  TorchAudio  |  Numba\n",
            "1 threads: --------------------------------------------------------------------------------------------------------\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[92m\u001b[1m    1.3   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  4.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[34m\u001b[1m    1.4   \u001b[0m\u001b[0m  |    5.4\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.4\n",
            "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[34m\u001b[1m  4.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[2m\u001b[91m    6.0   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  4.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m    7.4   \u001b[0m\u001b[0m  |  \u001b[92m\u001b[1m  4.0\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[34m\u001b[1m  4.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[34m\u001b[1m  4.2\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.6     |  \u001b[34m\u001b[1m  4.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.6     |  \u001b[34m\u001b[1m  4.1\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.5\n",
            "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.6\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   12.3   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  4.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   16.0   \u001b[0m\u001b[0m  |  \u001b[34m\u001b[1m  4.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[34m\u001b[1m  4.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[34m\u001b[1m  4.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.1     |  \u001b[34m\u001b[1m  4.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.2     |  \u001b[34m\u001b[1m  4.3\u001b[0m\u001b[0m\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.7\n",
            "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.8\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   32.3   \u001b[0m\u001b[0m  |    4.4\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   31.7   \u001b[0m\u001b[0m  |    4.4\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    4.4\n",
            "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    4.4\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    4.4   \u001b[0m\u001b[0m  |    4.5\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    4.4   \u001b[0m\u001b[0m  |    4.6\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.6\n",
            "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.7\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   71.8   \u001b[0m\u001b[0m  |    6.2\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   63.9   \u001b[0m\u001b[0m  |    6.2\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    6.2\n",
            "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    6.2\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.4     |    7.4\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.5     |    7.4\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    7.6\n",
            "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    7.9\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   10.5   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  9.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   12.3   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  8.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m  8.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m  9.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    6.2   \u001b[0m\u001b[0m  |    7.5\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    6.4   \u001b[0m\u001b[0m  |    7.5\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    7.7\n",
            "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m  8.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   31.2   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 11.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   40.4   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 12.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 12.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    4.8   \u001b[0m\u001b[0m  |    7.7\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    4.8   \u001b[0m\u001b[0m  |    7.6\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m  8.3\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m  8.7\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   45.0   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   43.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.0\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 12.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 12.1\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m    9.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  8.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   10.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m  8.8\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m  9.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m  9.4\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   88.3   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 19.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   84.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 18.9\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 19.2\u001b[0m\u001b[0m\n",
            "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 19.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[2m\u001b[91m    4.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[2m\u001b[91m    4.7   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 12.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 13.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 13.5\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   20.7   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 16.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   24.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 16.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[2m\u001b[91m 16.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[2m\u001b[91m 16.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m    8.8   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m    8.9   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 13.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 14.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   42.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   51.8   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 22.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 22.3\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m    8.5   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m    8.6   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 13.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 14.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 14.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m   64.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m   63.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 22.6\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 22.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001b[31m\u001b[1m   16.1   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 15.7\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001b[31m\u001b[1m   16.4   \u001b[0m\u001b[0m  |  \u001b[2m\u001b[91m 15.4\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001b[2m\u001b[91m 16.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001b[2m\u001b[91m 16.8\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001b[31m\u001b[1m  135.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 36.0\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001b[31m\u001b[1m  142.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 36.1\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 36.2\u001b[0m\u001b[0m\n",
            "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 35.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m    7.7   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.4\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m    7.8   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 22.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 25.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 25.4\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m   40.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 30.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m   46.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 30.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 31.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 31.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   18.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 24.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   18.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 24.5\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 27.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 28.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m   95.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 43.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  118.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 42.9\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 43.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 43.1\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   15.6   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 24.4\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   15.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 24.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 27.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 28.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  164.8   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 43.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  167.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 43.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 43.7\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 44.4\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   34.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 29.6\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   35.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 30.3\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 30.8\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 31.2\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  292.5   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 71.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  315.3   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 71.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 71.0\u001b[0m\u001b[0m\n",
            "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 71.3\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   15.9   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 42.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   16.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 43.3\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 49.0\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 49.4\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m   81.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 62.0\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m   97.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 62.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 60.7\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 60.8\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   32.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 47.8\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   32.7   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 48.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 58.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 55.4\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  171.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 84.9\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  205.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 85.5\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 85.1\u001b[0m\u001b[0m\n",
            "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 85.4\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   29.0   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 48.6\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   29.2   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 47.8\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 54.6\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 55.5\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001b[31m\u001b[1m  239.1   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 86.5\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001b[31m\u001b[1m  251.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 85.7\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m 86.0\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m 86.6\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001b[31m\u001b[1m   67.4   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 57.8\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001b[31m\u001b[1m   68.7   \u001b[0m\u001b[0m  |  \u001b[31m\u001b[1m 58.0\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m 58.7\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m 59.1\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |              |  \u001b[31m\u001b[1m145.5\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |              |  \u001b[31m\u001b[1m145.7\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001b[31m\u001b[1m146.2\u001b[0m\u001b[0m\n",
            "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001b[31m\u001b[1m146.3\u001b[0m\u001b[0m\n",
            "\n",
            "Times are in milliseconds (ms).\n",
            "\n"
          ]
        }
      ]
    }
  ]
}