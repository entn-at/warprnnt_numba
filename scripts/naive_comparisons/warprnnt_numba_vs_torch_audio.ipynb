{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "warprnnt_numba_vs_torch_audio.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aq4tJykSe_eE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "23f28d40-95ff-4076-b008-7ef5afcc22a7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (0.51.2)\n",
      "Collecting numba\n",
      "  Downloading numba-0.55.1-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 14.1 MB/s \n",
      "\u001B[?25hCollecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 34.5 MB 10 kB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy<1.22,>=1.18 in /usr/local/lib/python3.7/dist-packages (from numba) (1.19.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (57.4.0)\n",
      "Installing collected packages: llvmlite, numba\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.34.0\n",
      "    Uninstalling llvmlite-0.34.0:\n",
      "      Successfully uninstalled llvmlite-0.34.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.51.2\n",
      "    Uninstalling numba-0.51.2:\n",
      "      Successfully uninstalled numba-0.51.2\n",
      "Successfully installed llvmlite-0.38.0 numba-0.55.1\n"
     ]
    }
   ],
   "source": [
    "# Update numba and restart\n",
    "\n",
    "# In a conda environment, you would use the following command\n",
    "# Update Numba to > 0.54\n",
    "# conda install -c conda-forge numba>=0.54\n",
    "# or\n",
    "# conda update -c conda-forge numba>=0.54\n",
    "\n",
    "# For pip based environments,\n",
    "# Update Numba to > 0.54\n",
    "import os\n",
    "import signal\n",
    "\n",
    "!pip install --upgrade numba\n",
    "\n",
    "# This will kill the kernel, click next cell to import the latest numba\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive comparison between WarpRNNT Numba and Torchaudio RNNT [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/titu1994/warprnnt_numba/blob/master/scripts/naive_comparisons/warprnnt_numba_vs_torch_audio.ipynb)\n",
    "\n",
    "This notebook is a colab compatible way to do a **naive comparison** between the two loss functions. \n",
    "\n",
    "*Therefore no conclusions can be reached from this notebook, both are useful in many contexts.*\n",
    "\n",
    "-----\n",
    "\n",
    "Note that due to some dangling reference issue with running PyTorch `benchmark.Timer` with global variables for the inputs to the function, we will be writing the code in the notebook and in parallel exporting  the code snippets into a new file called `script.py` which will then be executed to write out the results.\n",
    "\n",
    "-----\n",
    "\n",
    "## THIS NOTEBOOK MUST BE RUN TOP TO BOTTOM ONLY. \n",
    "\n",
    "-----\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "EHaf-XbRrZws"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check that a recent Numba version has been installed. Anything > 0.53 will do."
   ],
   "metadata": {
    "id": "83b1lg7Tsd8Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numba\n",
    "print(numba.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84lf3plWf6c-",
    "outputId": "784b7e91-3053-4d10-f974-24541b35e7e9"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.55.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install the `warprnnt_numba` library from https://github.com/titu1994/warprnnt_numba.git"
   ],
   "metadata": {
    "id": "3h6YpSg9so89"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install git+https://github.com/titu1994/warprnnt_numba.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmgxiF1vfqa0",
    "outputId": "fe692fd1-b55d-4767-f848-72c39dbf7239"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/titu1994/warprnnt_numba.git\n",
      "  Cloning https://github.com/titu1994/warprnnt_numba.git to /tmp/pip-req-build-ue48zzt4\n",
      "  Running command git clone -q https://github.com/titu1994/warprnnt_numba.git /tmp/pip-req-build-ue48zzt4\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from warprnnt-numba==0.2.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from warprnnt-numba==0.2.3) (0.55.1)\n",
      "Requirement already satisfied: numpy<1.22,>=1.18 in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.2.3) (1.19.5)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.2.3) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->warprnnt-numba==0.2.3) (57.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->warprnnt-numba==0.2.3) (3.10.0.2)\n",
      "Building wheels for collected packages: warprnnt-numba\n",
      "  Building wheel for warprnnt-numba (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for warprnnt-numba: filename=warprnnt_numba-0.2.3-py2.py3-none-any.whl size=35321 sha256=20ae883c2a2f8048bf722e1b42769f224020fd12daefe2349902eeaeb19634fc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kf6n51lj/wheels/4f/a0/b1/077219f288994e18d6b0fb5bf326931aecce95cdc804e5203d\n",
      "Successfully built warprnnt-numba\n",
      "Installing collected packages: warprnnt-numba\n",
      "Successfully installed warprnnt-numba-0.2.3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility IPython Magic functions\n",
    "\n",
    "The following two functions are to denote cells that export their code content into `scripts.py`. \n",
    "\n",
    "-----\n",
    "\n",
    "## NOTE\n",
    "\n",
    "Rerunning a cell multiple times will duplicate the code inside the script, so only run this notebook top to bottom and return here to run again !"
   ],
   "metadata": {
    "id": "7UylHQf4svkF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def exec_write_cell(line, cell):\n",
    "    # Run and save python code block to a file\n",
    "\n",
    "    with open(line, 'a', encoding='utf8') as pyf:\n",
    "        pyf.write(cell)\n",
    "        pyf.write(\"\\n\\n\")\n",
    "\n",
    "    code = compile(cell, line, 'exec')\n",
    "    exec(code, globals())\n",
    "    print(\"---> wrote cells to file :\", line)\n",
    "\n",
    "@register_cell_magic\n",
    "def write_cell(line, cell):\n",
    "    # Save python code block to a file, but do not run it.\n",
    "\n",
    "    with open(line, 'a', encoding='utf8') as pyf:\n",
    "        pyf.write(cell)\n",
    "        pyf.write(\"\\n\\n\")\n",
    "\n",
    "    print(\"---> wrote cells to file (and did not execute):\", line)"
   ],
   "metadata": {
    "id": "7SffNvdEWbWG"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Be sure to delete the file cells if creating a new \n",
    "if os.path.exists('script.py'):\n",
    "  os.remove('script.py')"
   ],
   "metadata": {
    "id": "neo_P7eUYbg-"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "\n",
    "print(\"Torch :\", torch.__version__)\n",
    "print(\"Torch Audio:\", torchaudio.__version__)\n",
    "print(\"[Note]: Torch audio version must be >= 0.10.0\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdvtukmUgrLA",
    "outputId": "59dc0c72-1f27-4ea6-b7c5-a41a535613aa"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torch : 1.10.0+cu111\n",
      "Torch Audio: 0.10.0+cu111\n",
      "[Note]: Torch audio version must be >= 0.10.0\n",
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "import warprnnt_numba\n",
    "print(\"warprnnt_numba:\", warprnnt_numba.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgGYHW9qfkAv",
    "outputId": "af84fb46-bd57-4b26-dd16-11977fa53158"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "warprnnt_numba: 0.2.3\n",
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "import numba\n",
    "cuda_supported = warprnnt_numba.numba_utils.numba_cuda_is_supported(numba.__version__)\n",
    "print(\"Numba supports CUDA:\", cuda_supported)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtPbeoKalFNo",
    "outputId": "f9044509-9967-4eed-ab36-419f2f380fff"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numba supports CUDA: True\n",
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper methods \n",
    "\n",
    "Below are some helper methods that will build the loss functions and then call them on some random data. \n",
    "\n",
    "-----\n",
    "\n",
    "Note that for a given set of input arguments to `data_gen()`, the seeds are set in such a way that if the shape matches (via variable `bs`, `t`, `u` and `v`) then the same tensor is generated. This is for fair comparison between same inputs for two different loss functions. "
   ],
   "metadata": {
    "id": "JxAyYxYz1-3D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import subprocess\n",
    "import traceback\n",
    "\n",
    "import torch\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "from torchaudio.transforms import RNNTLoss\n",
    "from warprnnt_numba.rnnt_loss import RNNTLossNumba\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'"
   ],
   "metadata": {
    "id": "msYY_7CejIUX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "221d5a8f-5d1c-4ff3-86fc-e061f3c58b15"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Losses\n",
    "\n",
    "For comparison, we use <br>\n",
    "1) Torchaudio RNNT Loss <br>\n",
    "2) Numba WarpRNNT Loss <br>\n",
    "\n",
    "-----\n",
    "\n",
    "Differences between the two losses - \n",
    "* Torchaudio does not currently support [FastEmit Regulization](https://arxiv.org/abs/2010.11148). For such cases we skip the calculation of the loss and leave the result a blank row.\n",
    "\n",
    "* Numba does not currently support float16 CUDA calls, therefore we will test only fp32. If a fp16 tensor is passed to Numba loss, it will explicitly upcast it fp32 before computing the loss (at the cost of 2x memory for the input tensor). \n",
    "\n",
    "* Sometimes at Batch size 32 and large dimensions of T, U and V, Torchaudio RNNT loss sometimes hard crashes with cuda illegal memory access error. Its not always, but when it occurs try catch doesnt help since it corrupts the CUDA context and requires the script to be rerun. Maybe its something with GPU config but I havent debugged it, so for now those configurations will be commented out and skipped.\n"
   ],
   "metadata": {
    "id": "B5XTtQCRuHkX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "global x, x_len, y, y_len\n",
    "\n",
    "def data_gen(bs, t=200, u=100, v=1024, dtype=torch.float32):\n",
    "    global x, x_len, y, y_len\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    shape = [bs, t, u, v + 1]\n",
    "    torch.manual_seed(0)\n",
    "    x = torch.randn(*shape, dtype=dtype, device=DEVICE, requires_grad=False)\n",
    "    x_len = torch.randint(t, size=[bs], device=DEVICE, dtype=torch.int32)\n",
    "    y = torch.randint(v, size=[bs, u - 1], device=DEVICE, dtype=torch.int32)\n",
    "    y_len = torch.randint(u, size=[bs], device=DEVICE, dtype=torch.int32)\n",
    "\n",
    "    # enforce some RNNT input constraints\n",
    "    rand_idx = torch.randint(bs, size=[1])\n",
    "    x_len[rand_idx] = t\n",
    "    y_len[rand_idx] = u - 1\n",
    "\n",
    "    return x, x_len, y, y_len\n",
    "\n",
    "\n",
    "def check_time_pt(x, x_len, y, y_len, fastemit_lambda=None, clamp=-1.0):\n",
    "    blank = x.shape[-1] - 1\n",
    "    rnnt_loss = RNNTLoss(blank=blank, clamp=clamp, reduction=\"none\")\n",
    "\n",
    "    try:\n",
    "        _ = rnnt_loss(logits=x, targets=y, logit_lengths=x_len, target_lengths=y_len)\n",
    "    except NotImplementedError:\n",
    "        print()\n",
    "        print(\"RNNT Loss not available on this platform. Could not compute Pytorch Audio RNNT Loss.\")\n",
    "        print(\"Original error below :\")\n",
    "        print(traceback.format_exc())\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "def check_time_numba(x, x_len, y, y_len, fastemit_lambda=0.0, clamp=-1.0):\n",
    "    blank = x.shape[-1] - 1\n",
    "    rnnt_loss = RNNTLossNumba(blank=blank, reduction='none', fastemit_lambda=fastemit_lambda, clamp=clamp)\n",
    "\n",
    "    # Numba doesnt support fp16\n",
    "    if x.dtype != torch.float32:\n",
    "        x = x.float()\n",
    "\n",
    "    _ = rnnt_loss(acts=x, labels=y, act_lens=x_len, label_lens=y_len)\n",
    "\n",
    "\n",
    "def load_results(path):\n",
    "  with open(path, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    return results\n",
    "\n",
    "def save_results(results, path):\n",
    "  with open(path, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ],
   "metadata": {
    "id": "TnhYfzIolEFV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "09658508-ca17-4d89-c18e-b56cefe79363"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## System Info\n",
    "\n",
    "The script should emit some key info such as which GPU is being used, how much memory it has and how much is free/allocated at the moment."
   ],
   "metadata": {
    "id": "8WrQLJnLwKGm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "# Print CUDA environment\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, encoding='utf-8')\n",
    "print(result.stdout)\n",
    "result = subprocess.run(['nvidia-smi', '-L'], capture_output=True, text=True, encoding='utf-8')\n",
    "print(result.stdout)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VR6N8mNC3aNI",
    "outputId": "b47397fe-9255-4bee-bac1-5a27aabf769c"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sat Jan 29 21:10:16 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   63C    P8    11W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "GPU 0: Tesla T4 (UUID: GPU-97bc1480-6596-6896-a3e3-f80c6abafd3b)\n",
      "\n",
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(\"GPU Memory :\", torch.cuda.memory_summary())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIoG4_mq5Uw7",
    "outputId": "86919183-5b64-43f8-e41a-7cf5a52fcff3"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU Memory : |===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "basedir = f\"results/numba_vs_torch_audio/\"\n",
    "if not os.path.exists(basedir):\n",
    "    os.makedirs(basedir, exist_ok=True)"
   ],
   "metadata": {
    "id": "YDpe6z_e6TCB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8ab7b34e-4b10-45f9-c85b-54ba701a2cac"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Core script\n",
    "\n",
    "This cell is the main portion of the notebook, which normally should execute with certain combinations noted below.\n",
    "\n",
    "However, during testing it seems memory is not properly released inside the loop even with explicit None cast and global variables to prevent duplicate referrences. So this snippet simply writes out to the script instead of executing itself.\n",
    "\n",
    "-----\n",
    "\n",
    "### Permutations\n",
    "\n",
    "The ranges have been selected for general Librispeech training. \n",
    "\n",
    "Batch size depends on the variable `REQUIRES_GRAD`. Since gradient shape is same as shape of the input joint, it requires roughly 2x the memory so batch size must be halved. \n",
    "\n",
    "* `b`: [1, 4, 8, 16]. [32] is added if loss is being computed for inference only. 32 GB memory can go upto 64 with Numba for inference and 32 for training.\n",
    "* `t`: [200, 400]. Average length of LS is 16 seconds, with 4x stride ~ 400 timesteps, and with 8x stride of encoder its ~ 200 timesteps.\n",
    "* `u`: [100, 200]. Depends on how the text was encoded - character encoding (upto 400+ characters) to subword encoding (100-200 sub-words). \n",
    "* `v`: [28, 1024]. Represents vocabulary size of the model. 28 is for character encoding - 26 lower case alphabet, space and apostrophe. 1024 is for sub-word encoding with fixed vocabulary size - Google papers tend towards 1024 for their RNNT models (though some are upto 4096).\n",
    "* `fastemit_lambda`: [0.0, 0.001]. FastEmit regularization strength. 0.0 means it is disabled, and any value > 0 will perform fastemit regularization for numba loss. Skipped for Torchaudio loss.\n",
    "* `dtype`: [torch.float32]. Fixed to float32 for now, since we cant do the largest test suite due to memory constraints. Will be removed once numba supports float16 for CUDA.\n",
    "* `clamp`: [-1, 0.1]. Factor for gradient clamping. If -1, it is disabled and any value > 0 will enable the gradient clamping step in numba and torchaudio losses."
   ],
   "metadata": {
    "id": "OH3xcfBewVFF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%exec_write_cell script.py\n",
    "\n",
    "REQUIRES_GRAD = True\n",
    "\n",
    "print(\"Gradients will be computed :\", REQUIRES_GRAD)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSn9sOKUv_UI",
    "outputId": "c38674e4-6ea2-4172-c452-7af7e6d3b583"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Gradients will be computed : True\n",
      "---> wrote cells to file : script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%write_cell script.py\n",
    "\n",
    "# Compare takes a list of measurements which we'll save in results.\n",
    "global results\n",
    "results = []\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
    "save_results(results, results_path)\n",
    "del results\n",
    "\n",
    "\n",
    "batchsizes = [1, 4, 8, 16]\n",
    "\n",
    "if not REQUIRES_GRAD:\n",
    "  batchsizes.append(32)\n",
    "\n",
    "for b in batchsizes:  # 1, 4, 8, 16, 32, 64 (on 32 GB GPUs)\n",
    "    for t in [200, 400]:  # 200, 400, 600 (LibriSpeech with 4x and 8x stride, on 32 GB GPUs)\n",
    "        for u in [100, 200]:  # 100, 200  # (char enc, subword enc)\n",
    "            for v in [28, 1024,]:  # 28, 1024  # (char encoding, Conformer RNNT Vocab Size)\n",
    "                for fastemit_lambda in [0.0, 0.001]:  # 0.0, 0.001  # (Google FastEmit regularization, no extra memory)\n",
    "                    for dtype in [torch.float32]:  # (AMP / FP32; Note: Numba impl will force cast to fp32)\n",
    "                        for clamp in [-1.0, 0.1]:  # Gradient clamping\n",
    "                            global x, x_len, y, y_len\n",
    "                            x = None\n",
    "                            x_len = None\n",
    "                            y = None\n",
    "                            y_len = None\n",
    "\n",
    "                            torch.cuda.empty_cache()\n",
    "\n",
    "                            # label and sub_label are the rows\n",
    "                            # description is the column\n",
    "                            label = 'RNNTLoss'\n",
    "                            sub_label = (\n",
    "                                f'[b={b}, t={t}, u={u}, v={v}, '\n",
    "                                f'fastemit_lambda={fastemit_lambda}, '\n",
    "                                f'clamp={clamp}, '\n",
    "                                f'dtype={dtype}]'\n",
    "                            )\n",
    "\n",
    "                            print(\"Computing :\", sub_label)\n",
    "\n",
    "                            # Pytorch Audio\n",
    "                            env = 'TorchAudio'\n",
    "\n",
    "                            if fastemit_lambda == 0.0:\n",
    "                                x, x_len, y, y_len = data_gen(b, t, u, v, dtype=dtype)\n",
    "\n",
    "                                if REQUIRES_GRAD:\n",
    "                                  x.requires_grad = True\n",
    "\n",
    "                                # Weird case of cuda illegal mem access beyond this config for fp 16 / fp 32 for batchsize=32\n",
    "                                # TODO: debug if its hardware issue or something else.\n",
    "                                # Works uptil b=32, t=329, u=200, v=1024 then fails above that for fp16\n",
    "                                # Also, setup b=32, t=600, u=100, v=1024 and above fails for fp32\n",
    "                                if (b * t * u * v) < (2 ** 31):\n",
    "                                    # fmt: off\n",
    "                                    t0 = benchmark.Timer(\n",
    "                                        stmt='check_time_pt(x, x_len, y, y_len, fastemit_lambda, clamp)',\n",
    "                                        setup=\"from __main__ import check_time_pt;\",\n",
    "                                        globals={'x': x, 'x_len': x_len, 'y': y, 'y_len': y_len,\n",
    "                                                  'fastemit_lambda': fastemit_lambda, 'clamp': clamp},\n",
    "                                        label=label,\n",
    "                                        sub_label=sub_label,\n",
    "                                        description=env,\n",
    "                                        num_threads=torch.get_num_threads(),\n",
    "                                    ).blocked_autorange(min_run_time=1.0)\n",
    "                                    # fmt: on\n",
    "\n",
    "                                    results = load_results(results_path)\n",
    "                                    results.append(t0)\n",
    "                                    save_results(results, results_path)\n",
    "                                    del results, t0\n",
    "                                    \n",
    "                                del x, x_len, y_len\n",
    "                                \n",
    "                            torch.cuda.empty_cache()\n",
    "\n",
    "                            # Numba\n",
    "                            env = 'Numba'\n",
    "                            x, x_len, y, y_len = data_gen(b, t, u, v, dtype=dtype)\n",
    "\n",
    "                            if REQUIRES_GRAD:\n",
    "                                  x.requires_grad = True\n",
    "\n",
    "                            # fmt: off\n",
    "                            t0 = benchmark.Timer(\n",
    "                                stmt='check_time_numba(x, x_len, y, y_len, fastemit_lambda, clamp);',\n",
    "                                setup=\"from __main__ import check_time_numba;\",\n",
    "                                globals={'x': x, 'x_len': x_len, 'y': y, 'y_len': y_len,\n",
    "                                          'fastemit_lambda': fastemit_lambda, 'clamp': clamp},\n",
    "                                label=label,\n",
    "                                sub_label=sub_label,\n",
    "                                description=env,\n",
    "                                num_threads=torch.get_num_threads(),\n",
    "                            ).blocked_autorange(min_run_time=1.0)\n",
    "                            # fmt: on\n",
    "\n",
    "                            results = load_results(results_path)\n",
    "                            results.append(t0)\n",
    "                            save_results(results, results_path)\n",
    "                            del results, t0\n",
    "\n",
    "                            del x, x_len, y, y_len\n",
    "                            torch.cuda.empty_cache()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPDUgiZhlTEJ",
    "outputId": "2685b4c0-096b-4057-b849-7e6c060d7d15"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---> wrote cells to file (and did not execute): script.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execute script\n",
    "\n",
    "Now that the script has the code contents necessary to perform the evaluations, execute it from the shell"
   ],
   "metadata": {
    "id": "FctYHrZLzV1x"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training mode"
   ],
   "metadata": {
    "id": "-3BS1JaVy8v_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python script.py"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xqum-zROWpLC",
    "outputId": "57f16925-5348-4e55-bccb-0cc681306529"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torch : 1.10.0+cu111\n",
      "Torch Audio: 0.10.0+cu111\n",
      "[Note]: Torch audio version must be >= 0.10.0\n",
      "warprnnt_numba: 0.2.3\n",
      "Numba supports CUDA: True\n",
      "Sat Jan 29 21:11:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   57C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "GPU 0: Tesla T4 (UUID: GPU-97bc1480-6596-6896-a3e3-f80c6abafd3b)\n",
      "\n",
      "GPU Memory : |===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Gradients will be computed : True\n",
      "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (4) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (8) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (16) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print out results\n",
    "\n",
    "Since the output has been written to a pickle file, print out the output of the script above."
   ],
   "metadata": {
    "id": "aOtw0lHxz2lO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print()\n",
    "print()\n",
    "\n",
    "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
    "results = load_results(results_path)\n",
    "compare = benchmark.Compare(results)\n",
    "compare.colorize()\n",
    "compare.print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y80iSqdMlV1s",
    "outputId": "6add0ca2-7ae5-43b7-8691-fa55b4de788f"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "[---------------------------------------------------- RNNTLoss ---------------------------------------------------]\n",
      "                                                                                            |  TorchAudio  |  Numba\n",
      "1 threads: --------------------------------------------------------------------------------------------------------\n",
      "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[92m\u001B[1m    1.3   \u001B[0m\u001B[0m  |    7.0\n",
      "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[34m\u001B[1m    1.4   \u001B[0m\u001B[0m  |  \u001B[92m\u001B[1m  6.3\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[34m\u001B[1m  6.6\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[34m\u001B[1m  6.7\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[2m\u001B[91m    6.1   \u001B[0m\u001B[0m  |    8.7\n",
      "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m    7.6   \u001B[0m\u001B[0m  |    8.8\n",
      "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    8.7\n",
      "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    8.6\n",
      "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.6     |  \u001B[34m\u001B[1m  6.8\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    2.7   \u001B[0m\u001B[0m  |  \u001B[34m\u001B[1m  6.7\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[34m\u001B[1m  6.9\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    7.0\n",
      "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   12.6   \u001B[0m\u001B[0m  |   12.5\n",
      "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   16.7   \u001B[0m\u001B[0m  |   12.5\n",
      "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |   12.3\n",
      "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |   12.4\n",
      "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.2     |  \u001B[34m\u001B[1m  6.7\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.3     |  \u001B[34m\u001B[1m  6.7\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[34m\u001B[1m  6.7\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[34m\u001B[1m  6.8\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   32.3   \u001B[0m\u001B[0m  |   12.6\n",
      "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   33.7   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 12.8\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |   12.6\n",
      "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m 12.7\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    4.5   \u001B[0m\u001B[0m  |    7.5\n",
      "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    4.6   \u001B[0m\u001B[0m  |    7.7\n",
      "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    7.3\n",
      "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    7.3\n",
      "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   71.8   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 24.4\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   66.5   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 24.5\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[2m\u001B[91m 24.0\u001B[0m\u001B[0m\n",
      "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m 24.1\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.5     |   10.3\n",
      "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.5     |   10.5\n",
      "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |   11.1\n",
      "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |   11.3\n",
      "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   10.5   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 16.7\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   12.1   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 16.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[2m\u001B[91m 16.7\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m 16.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    6.2   \u001B[0m\u001B[0m  |   12.2\n",
      "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    6.3   \u001B[0m\u001B[0m  |   11.9\n",
      "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |   12.1\n",
      "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |   11.8\n",
      "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   30.4   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 34.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   38.7   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 34.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 34.2\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 34.4\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    4.7   \u001B[0m\u001B[0m  |   11.4\n",
      "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    4.8   \u001B[0m\u001B[0m  |   11.4\n",
      "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |   11.3\n",
      "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |   11.4\n",
      "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   43.1   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 30.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   43.9   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 31.3\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[2m\u001B[91m 30.6\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m 30.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[31m\u001B[1m   10.0   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 14.7\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[31m\u001B[1m   10.1   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 14.6\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 14.6\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 14.6\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   88.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 53.2\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   85.9   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 53.3\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 52.7\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 52.7\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    4.6   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 16.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    4.8   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 16.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 16.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 17.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   20.3   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 33.1\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   24.3   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 33.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 32.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 32.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[31m\u001B[1m    8.8   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 18.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[31m\u001B[1m    8.8   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 17.6\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 17.7\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 17.5\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   42.7   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 56.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   51.7   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 57.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 56.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 56.5\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[31m\u001B[1m    8.5   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 18.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[31m\u001B[1m    8.6   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 18.2\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 18.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 18.2\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   64.2   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 54.1\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   61.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 54.3\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 53.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 53.6\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[31m\u001B[1m   16.1   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 25.5\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[31m\u001B[1m   16.6   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 25.5\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 25.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 25.1\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m  137.6   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m110.7\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m  142.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m110.8\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m108.5\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m108.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m    7.8   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 27.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m    7.9   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 27.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m 28.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 30.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m   40.4   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 64.8\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m   46.4   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 65.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m 64.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 64.8\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   18.1   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 34.9\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   18.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 34.6\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 33.7\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 33.8\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m   95.7   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m125.0\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m  118.3   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m125.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m124.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m124.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   15.6   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 33.6\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   15.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 33.7\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 33.4\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 34.0\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m  167.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m131.6\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m  171.7   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m131.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m128.6\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m128.9\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   34.4   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 50.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   34.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 49.6\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 48.7\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 48.8\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m  296.0   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m245.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m  314.2   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m247.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m243.3\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m244.5\u001B[0m\u001B[0m\n",
      "\n",
      "Times are in milliseconds (ms).\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference Mode"
   ],
   "metadata": {
    "id": "E7_umfTVy51d"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!sed -i 's/REQUIRES_GRAD = True/REQUIRES_GRAD = False/g' script.py\n",
    "!python script.py"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EWrh_4Tyrap",
    "outputId": "400701a7-5902-4e67-a326-a1049484597a"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torch : 1.10.0+cu111\n",
      "Torch Audio: 0.10.0+cu111\n",
      "[Note]: Torch audio version must be >= 0.10.0\n",
      "warprnnt_numba: 0.2.3\n",
      "Numba supports CUDA: True\n",
      "Sat Jan 29 21:16:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   74C    P0    33W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "GPU 0: Tesla T4 (UUID: GPU-97bc1480-6596-6896-a3e3-f80c6abafd3b)\n",
      "\n",
      "GPU Memory : |===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Gradients will be computed : False\n",
      "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (1) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (4) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (8) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (16) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: Grid size (32) < 2 * SM count (80) will likely result in GPU under utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]\n",
      "Computing : [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print out results\n",
    "\n",
    "Since the output has been written to a pickle file, print out the output of the script above."
   ],
   "metadata": {
    "id": "VDf12SvNzUBe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print()\n",
    "print()\n",
    "\n",
    "results_path = os.path.join(basedir, 'rnnt_results.pkl')\n",
    "results = load_results(results_path)\n",
    "compare = benchmark.Compare(results)\n",
    "compare.colorize()\n",
    "compare.print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oVfaIEgzGIZ",
    "outputId": "c8d89c02-0b2e-472b-cb3f-838cc11412c5"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "[---------------------------------------------------- RNNTLoss ---------------------------------------------------]\n",
      "                                                                                            |  TorchAudio  |  Numba\n",
      "1 threads: --------------------------------------------------------------------------------------------------------\n",
      "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[92m\u001B[1m    1.3   \u001B[0m\u001B[0m  |    4.3\n",
      "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[34m\u001B[1m    1.4   \u001B[0m\u001B[0m  |  \u001B[92m\u001B[1m  3.8\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.3\n",
      "      [b=1, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.3\n",
      "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[2m\u001B[91m    6.3   \u001B[0m\u001B[0m  |  \u001B[34m\u001B[1m  4.1\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m    7.9   \u001B[0m\u001B[0m  |  \u001B[34m\u001B[1m  4.1\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[34m\u001B[1m  4.1\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[34m\u001B[1m  4.2\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    2.7   \u001B[0m\u001B[0m  |  \u001B[34m\u001B[1m  4.2\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    2.8   \u001B[0m\u001B[0m  |  \u001B[34m\u001B[1m  4.2\u001B[0m\u001B[0m\n",
      "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.5\n",
      "      [b=1, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.6\n",
      "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   13.2   \u001B[0m\u001B[0m  |    4.4\n",
      "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   17.5   \u001B[0m\u001B[0m  |    4.4\n",
      "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    4.3\n",
      "      [b=1, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    4.3\n",
      "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.2     |    4.2\n",
      "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.3     |    4.3\n",
      "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.6\n",
      "      [b=1, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.8\n",
      "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   34.3   \u001B[0m\u001B[0m  |    4.4\n",
      "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   31.9   \u001B[0m\u001B[0m  |    4.4\n",
      "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    4.5\n",
      "      [b=1, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    4.4\n",
      "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    4.5   \u001B[0m\u001B[0m  |    4.6\n",
      "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    4.5   \u001B[0m\u001B[0m  |    4.6\n",
      "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    4.8\n",
      "      [b=1, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |    4.7\n",
      "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   71.4   \u001B[0m\u001B[0m  |    6.2\n",
      "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   64.0   \u001B[0m\u001B[0m  |    6.2\n",
      "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |    6.2\n",
      "      [b=1, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |    6.2\n",
      "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |      2.4     |    7.5\n",
      "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |      2.5     |    7.4\n",
      "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |    7.5\n",
      "      [b=4, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m  7.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   10.3   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m  8.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   12.1   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m  8.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[2m\u001B[91m  8.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m  9.0\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    6.2   \u001B[0m\u001B[0m  |    7.6\n",
      "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    6.3   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m  7.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m  8.3\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m  8.5\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   30.6   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 12.1\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   39.2   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 12.1\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[2m\u001B[91m 12.0\u001B[0m\u001B[0m\n",
      "      [b=4, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m 12.0\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    4.7   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m  8.0\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    4.9   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m  7.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m  8.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m  8.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   42.6   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 12.3\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   43.8   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 12.0\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[2m\u001B[91m 12.2\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m 12.2\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[31m\u001B[1m   10.0   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m  8.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[31m\u001B[1m   10.1   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m  8.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m  8.9\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m  9.1\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   89.0   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 19.3\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   87.0   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 18.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[2m\u001B[91m 18.8\u001B[0m\u001B[0m\n",
      "      [b=4, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 19.2\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[2m\u001B[91m    4.6   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 12.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[2m\u001B[91m    4.7   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 11.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 12.7\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 13.6\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   20.4   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 16.6\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   23.8   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 16.3\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[2m\u001B[91m 16.8\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[2m\u001B[91m 16.3\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[31m\u001B[1m    8.7   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 12.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[31m\u001B[1m    8.8   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 13.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 14.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 14.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   42.1   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 22.3\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   51.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 22.3\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 22.7\u001B[0m\u001B[0m\n",
      "      [b=8, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 22.5\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[31m\u001B[1m    8.5   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 13.6\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[31m\u001B[1m    8.6   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 13.1\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 14.0\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 15.3\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m   64.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 22.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m   63.1   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 22.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 22.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 22.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]       |  \u001B[31m\u001B[1m   16.1   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 15.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]        |  \u001B[31m\u001B[1m   16.2   \u001B[0m\u001B[0m  |  \u001B[2m\u001B[91m 15.6\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]     |              |  \u001B[2m\u001B[91m 15.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]      |              |  \u001B[2m\u001B[91m 16.4\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]     |  \u001B[31m\u001B[1m  134.2   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 35.9\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]      |  \u001B[31m\u001B[1m  144.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 35.8\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 35.8\u001B[0m\u001B[0m\n",
      "      [b=8, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 36.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m    7.7   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 22.3\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m    7.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 22.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 24.7\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 25.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m   40.2   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 31.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m   47.0   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 31.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m 31.4\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 31.6\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   18.2   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 24.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   18.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 24.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 26.9\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 28.3\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m   94.3   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 43.6\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m  118.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 43.4\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m 43.4\u001B[0m\u001B[0m\n",
      "      [b=16, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 43.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   15.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 24.2\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   15.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 24.5\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 26.8\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 28.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m  166.6   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 43.3\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m  167.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 42.9\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m 43.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 42.9\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   34.0   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 29.1\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   35.1   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 29.5\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 30.0\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 30.5\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m  291.4   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 70.5\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m  314.4   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 70.8\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m 70.5\u001B[0m\u001B[0m\n",
      "      [b=16, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 70.0\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   15.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 42.6\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   16.2   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 43.1\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 48.2\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 48.4\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m   81.1   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 60.4\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m   96.7   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 60.4\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m 60.0\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 60.6\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   32.0   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 47.3\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   32.4   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 47.2\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 52.6\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 55.1\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m  170.5   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 83.7\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m  202.3   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 84.8\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m 84.1\u001B[0m\u001B[0m\n",
      "      [b=32, t=200, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 84.9\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   28.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 48.2\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   29.2   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 47.0\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 53.1\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=100, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 54.8\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |  \u001B[31m\u001B[1m  238.8   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 84.1\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |  \u001B[31m\u001B[1m  249.9   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 84.2\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m 84.8\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=100, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m 84.7\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]      |  \u001B[31m\u001B[1m   67.0   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 56.0\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]       |  \u001B[31m\u001B[1m   68.7   \u001B[0m\u001B[0m  |  \u001B[31m\u001B[1m 56.6\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m 58.9\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=200, v=28, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m 57.6\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=-1.0, dtype=torch.float32]    |              |  \u001B[31m\u001B[1m144.3\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.0, clamp=0.1, dtype=torch.float32]     |              |  \u001B[31m\u001B[1m143.8\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=-1.0, dtype=torch.float32]  |              |  \u001B[31m\u001B[1m143.7\u001B[0m\u001B[0m\n",
      "      [b=32, t=400, u=200, v=1024, fastemit_lambda=0.001, clamp=0.1, dtype=torch.float32]   |              |  \u001B[31m\u001B[1m142.7\u001B[0m\u001B[0m\n",
      "\n",
      "Times are in milliseconds (ms).\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "q5c6QxuurbNO"
   },
   "execution_count": 18,
   "outputs": []
  }
 ]
}